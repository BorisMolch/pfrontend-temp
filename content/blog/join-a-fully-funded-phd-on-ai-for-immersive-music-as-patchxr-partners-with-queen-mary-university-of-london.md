+++
author = "PatchXR"
ctalink = ""
ctatext = ""
date = 2021-12-17T05:00:00Z
description = "In a unique research opportunity, we're proud to partner with Queen Mary University of London to offer a fully-funded, 4-year doctorate with the topic \" Multimodal AI for musical collaboration in immersive environments.\" Here's how to apply."
image = "/uploads/mileend.jpg"
title = "Apply for a fully-funded PhD on AI for immersive music, as PatchXR partners with Queen Mary University of London"
type = "post"

+++
![](/uploads/mileend.jpg)

The [**UKRI Centre for Doctoral Training in Artificial Intelligence and Music (AIM)**](https://www.aim.qmul.ac.uk/) is a PhD research programme based at Queen Mary University of London, specifically focused on creative industries and music. Partnership with industry helps them to foster a world-leading environment for research - and we're pleased to be one of the partners and doctoral topics for their 2022 call.

[Dr. Mathieu Barthet](http://www.eecs.qmul.ac.uk/profiles/barthetmathieu.html), Senior Lecturer in Digital Media at the [School of Electronic Engineering and Computer Science](http://eecs.qmul.ac.uk/) Queen Mary, is partnering with us to offer the chance to explore in depth a rich and in-demand topic:

**_Multimodal AI for musical collaboration in immersive environments_**

_There is little research on the application of automatic music generation using deep learning to immersive environments such as virtual reality (VR). VR lends itself well to AI-based interfaces for music co-creation given that it supports embodied interaction, audio, and visual feedback through animated avatars. Music making using VR musical instruments provides a way to collect multimodal data related to musical control, body language, spatial position, and musical content. Such rich amount of data can be harnessed to build intelligent systems for interactive musical collaboration between human and machines in VR._

_This PhD will research interactive music generation techniques facilitating musical collaborations between human and machine-based avatar performers in VR._

The research takes advantage of our deep platform for DSP and musical and visual interaction, expanding into the worlds of models for computer-supported cooperative work.

See the full description for details on the topic:

[https://www.aim.qmul.ac.uk/phd-topics/#PatchXR](https://www.aim.qmul.ac.uk/phd-topics/#PatchXR "https://www.aim.qmul.ac.uk/phd-topics/#PatchXR")

It's part of a singular four-year program, open to international and UK-based students, with applications now:

**UKRI Centre for Doctoral Training in Artificial Intelligence and Music (AIM)**

* 12+ Fully-funded PhD studentships to start September 2022
* Call open to UK Home and International student applicants 
* Covers fees and a stipend for four years
* Call opens on 1 December 2021 until 30 January 2022
* Access to cutting-edge facilities and expertise in artificial intelligence (AI) and music/audio technology
* Comprehensive technical training at the intersection of AI and music through a personalized programme

Apply at:

[https://www.aim.qmul.ac.uk/apply/](https://www.aim.qmul.ac.uk/apply/ "https://www.aim.qmul.ac.uk/apply/")